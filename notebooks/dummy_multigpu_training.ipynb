{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f92b47b-5a19-44b8-a4b7-51c210500135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/p/home/jusers/kotobi2/juwels/hida_project/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8e7e0d7-de86-423b-8640-ac889c4360d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b57aa9c-1a96-4509-87cd-fd92b6b5b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from attribution_gnn1.QM9_SpecData import QM9_SpecData\n",
    "from attribution_gnn1.split import save_split\n",
    "\n",
    "from attribution_gnn1.SpectraGNN import SpectraGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cf923eb-7a87-40cd-aff5-00f8044ecd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group, barrier\n",
    "import os\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "132a519b-6fc7-4801-a099-a9c471fb6e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = torch.cuda.device_count()\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"spectragatv2_multigpu.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcafc1d7-1d0b-4444-9d0d-cb22055779d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "230f85c5-0c0a-4797-9dc3-364cd44e49cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is not loaded\n"
     ]
    }
   ],
   "source": [
    "spectragnn = SpectraGNN(\n",
    "    gnn_name='gatv2',\n",
    "    in_channels=[11, 128, 256, 512],\n",
    "    out_channels=[128, 256, 512, 600],\n",
    "    num_targets=100,\n",
    "    num_layers=4,\n",
    "    heads=None\n",
    ").to(device)\n",
    "\n",
    "# loading the saved model \n",
    "path_to_model = osp.join('./best_model', \n",
    "                         model_name)\n",
    "\n",
    "if osp.exists(path_to_model):\n",
    "    spectragnn.load_state_dict(torch.load(path_to_model))\n",
    "else:\n",
    "    print('model is not loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7015323-df62-4db3-9a69-92fdcae5fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/p/home/jusers/kotobi2/juwels/data_qm9/all_graph_data/qm9_spec_10k.pt'\n",
    "qm9_spec = QM9_SpecData(root=root,\n",
    "             raw_dir='/p/home/jusers/kotobi2/juwels/data_qm9/raw/',\n",
    "             spectra=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9f137fd-a17b-4267-aa18-9a26dc1562a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = save_split(\n",
    "    path='/p/home/jusers/kotobi2/juwels/hida_project/data/split_files2/qm9_split_10k.npz',\n",
    "    ndata=len(qm9_spec),\n",
    "    ntrain=4000,\n",
    "    nval=1000,\n",
    "    ntest=0,\n",
    "    save_split=True,\n",
    "    shuffle=True, \n",
    "    print_nsample=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d9dfc57-b80e-4146-813c-dc90817c53a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qm9_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd4635f7-533c-44bf-9b39-59a4841e0867",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#train, val and test data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_qm9 \u001b[38;5;241m=\u001b[39m [qm9_spec[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idxs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      3\u001b[0m val_qm9 \u001b[38;5;241m=\u001b[39m [qm9_spec[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idxs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#test_qm9 = qm9_spec[idxs['test']]\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [12], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#train, val and test data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_qm9 \u001b[38;5;241m=\u001b[39m [\u001b[43mqm9_spec\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idxs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      3\u001b[0m val_qm9 \u001b[38;5;241m=\u001b[39m [qm9_spec[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idxs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#test_qm9 = qm9_spec[idxs['test']]\u001b[39;00m\n",
      "File \u001b[0;32m~/hida_project/attribution_gnn1/QM9_SpecData.py:180\u001b[0m, in \u001b[0;36mQM9_SpecData.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mint32, np\u001b[38;5;241m.\u001b[39mint64)):\n\u001b[0;32m--> 180\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[1;32m    182\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(idx)]\n",
      "File \u001b[0;32m~/hida_project/attribution_gnn1/QM9_SpecData.py:180\u001b[0m, in \u001b[0;36mQM9_SpecData.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mint32, np\u001b[38;5;241m.\u001b[39mint64)):\n\u001b[0;32m--> 180\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[1;32m    182\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(idx)]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#train, val and test data\n",
    "train_qm9 = [qm9_spec[i] for i in idxs['train']]\n",
    "val_qm9 = [qm9_spec[i] for i in idxs['val']]\n",
    "#test_qm9 = qm9_spec[idxs['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666e7c05-85e0-499f-a272-0c16193535b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75138d51-bab6-49bc-8bf2-d4ea463ec76a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 4 GPUs!\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLet\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms use\u001b[39m\u001b[38;5;124m'\u001b[39m, world_size, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPUs!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     58\u001b[0m args \u001b[38;5;241m=\u001b[39m (world_size, qm9_spec)\n\u001b[0;32m---> 59\u001b[0m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m        \n",
      "File \u001b[0;32m/p/software/juwelsbooster/stages/2020/software/PyTorch/1.8.1-gcccoremkl-10.3.0-2021.2.0-Python-3.8.5/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:230\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    226\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    227\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    228\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m torch.multiprocessing.start_process(...)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m start_method)\n\u001b[1;32m    229\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m--> 230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspawn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/p/software/juwelsbooster/stages/2020/software/PyTorch/1.8.1-gcccoremkl-10.3.0-2021.2.0-Python-3.8.5/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:173\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    171\u001b[0m processes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nprocs):\n\u001b[0;32m--> 173\u001b[0m     error_queue \u001b[38;5;241m=\u001b[39m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSimpleQueue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     process \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mProcess(\n\u001b[1;32m    175\u001b[0m         target\u001b[38;5;241m=\u001b[39m_wrap,\n\u001b[1;32m    176\u001b[0m         args\u001b[38;5;241m=\u001b[39m(fn, i, args, error_queue),\n\u001b[1;32m    177\u001b[0m         daemon\u001b[38;5;241m=\u001b[39mdaemon,\n\u001b[1;32m    178\u001b[0m     )\n\u001b[1;32m    179\u001b[0m     process\u001b[38;5;241m.\u001b[39mstart()\n",
      "File \u001b[0;32m/p/software/juwelsbooster/stages/2020/software/Python/3.8.5-GCCcore-10.3.0/lib/python3.8/multiprocessing/context.py:113\u001b[0m, in \u001b[0;36mBaseContext.SimpleQueue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m'''Returns a queue object'''\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqueues\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleQueue\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSimpleQueue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/p/software/juwelsbooster/stages/2020/software/Python/3.8.5-GCCcore-10.3.0/lib/python3.8/multiprocessing/queues.py:336\u001b[0m, in \u001b[0;36mSimpleQueue.__init__\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, ctx):\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mPipe(duplex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock \u001b[38;5;241m=\u001b[39m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mpoll\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/p/software/juwelsbooster/stages/2020/software/Python/3.8.5-GCCcore-10.3.0/lib/python3.8/multiprocessing/context.py:68\u001b[0m, in \u001b[0;36mBaseContext.Lock\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m'''Returns a non-recursive lock object'''\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msynchronize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Lock\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/p/software/juwelsbooster/stages/2020/software/Python/3.8.5-GCCcore-10.3.0/lib/python3.8/multiprocessing/synchronize.py:162\u001b[0m, in \u001b[0;36mLock.__init__\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, ctx):\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mSemLock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSEMAPHORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/p/software/juwelsbooster/stages/2020/software/Python/3.8.5-GCCcore-10.3.0/lib/python3.8/multiprocessing/synchronize.py:57\u001b[0m, in \u001b[0;36mSemLock.__init__\u001b[0;34m(self, kind, value, maxvalue, ctx)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m         sl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_semlock \u001b[38;5;241m=\u001b[39m \u001b[43m_multiprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSemLock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[43munlink_now\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "def run(rank, world_size, train_dataset):\n",
    "    #os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    #os.environ['MASTER_PORT'] = '12355'\n",
    "    #init_process_group('nccl', rank=rank, world_size=world_size)\n",
    "    init_process_group( \"nccl\", \"tcp://127.0.0.1:12345\", rank, world_size)\n",
    "    \n",
    "    data_sampler = DistributedSampler(train_dataset,\n",
    "                                      num_replicas=world_size,\n",
    "                                      rank=rank)\n",
    "    data_loader = DataLoader(train_dataset, batch_size=100, \n",
    "                             sampler=data_sampler, num_workers=0)\n",
    "    torch.manual_seed(12345)\n",
    "    model = SpectraGNN(\n",
    "            gnn_name='gatv2',\n",
    "            in_channels=[11, 128, 256, 512],\n",
    "            out_channels=[128, 256, 512, 600],\n",
    "            num_targets=100,\n",
    "            num_layers=4,\n",
    "            heads=None\n",
    "        ).to(rank)\n",
    "    model = DDP(model, device_ids=[rank])\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)\n",
    "    loss_fn = torch.nn.L1Loss()\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        \n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_graphs = 0\n",
    "        \n",
    "        for data in data_loader:\n",
    "            data = data.to(rank)\n",
    "            \n",
    "            x, edge_index, batch_seg = data.x, \\\n",
    "            data.edge_index, data.batch\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x, edge_index, batch_seg)\n",
    "            loss = loss_fn(pred.vies(-1, 1), \n",
    "                           data.spectrum.view(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss\n",
    "            total_graphs += data.num_graphs\n",
    "            \n",
    "        train_loss_avg = total_loss / total_graphs\n",
    "        \n",
    "        barrier()\n",
    "                    \n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"epoch {epoch} | average train loss = {train_loss_avg:.2f}\")\n",
    "            \n",
    "    destroy_process_group()\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    world_size = torch.cuda.device_count()\n",
    "    print('Let\\'s use', world_size, 'GPUs!')\n",
    "    args = (world_size, qm9_spec)\n",
    "    mp.spawn(run, args=args, nprocs=world_size, join=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665d83b0-1ad8-4882-afb0-53381f66a6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyG",
   "language": "python",
   "name": "pyg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
